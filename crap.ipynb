{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "# from selenium import webdriver\n",
    "from time import sleep as time_sleep\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import requests\n",
    "import subprocess\n",
    "from config import headers, cookies\n",
    "from pprint import pprint\n",
    "import lxml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the-mech-touch\n",
      "https://novelbin.com/ajax/chapter-option?novelId=the-mech-touch&currentChapterId\n"
     ]
    }
   ],
   "source": [
    "url_list = '''\n",
    "https://novelbin.com/b/the-mech-touch\n",
    "https://novelbin.com/b/shadow-slave\n",
    "'''.strip().split('\\n')\n",
    "\n",
    "\n",
    "url = url_list[0]\n",
    "\n",
    "host = '/'.join(url.split('/', maxsplit=3)[:3])\n",
    "name_title = url.split('/')[-1]\n",
    "print(name_title)\n",
    "\n",
    "chapters_link = f'{host}/ajax/chapter-option?novelId={name_title}&currentChapterId'\n",
    "print(chapters_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫ 5580\n",
      "–ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Å—ã–ª–∫–∞:\n",
      "https://novelbin.com/b/the-mech-touch/chapter-5580-divergent-paths\n"
     ]
    }
   ],
   "source": [
    "list_links = list()\n",
    "\n",
    "tt = requests.get(chapters_link, headers=headers, cookies=cookies)\n",
    "links_value = BS(tt.text, 'lxml')\n",
    "tb_list = links_value.find_all('option')\n",
    "elem : BS\n",
    "for elem in tb_list:\n",
    "    list_links.append(elem.get('value'))\n",
    "print('–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫',len(list_links))\n",
    "print('–ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Å—ã–ª–∫–∞:')\n",
    "print(list_links[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "driver = uc.Chrome()\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(host)\n",
    "time_sleep(1)\n",
    "driver.get(url)\n",
    "for _ in range(200):\n",
    "    page = driver.page_source\n",
    "    if not 'cloudflare.com' in page:\n",
    "        break\n",
    "    else:\n",
    "        time_sleep(1)\n",
    "else:\n",
    "    driver.quit()\n",
    "print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_eng = list()\n",
    "\n",
    "for link in list_links[400:600]:\n",
    "    driver.get(link)\n",
    "    for _ in range(200):\n",
    "        page = driver.page_source\n",
    "        if not 'cloudflare.com' in page:\n",
    "            break\n",
    "        else:\n",
    "            time_sleep(1)\n",
    "    else:\n",
    "        driver.quit()\n",
    "    time_sleep(0.5)\n",
    "    soup = BS(page, 'html.parser')\n",
    "    novel_title = soup.find(attrs={'class':'novel-title'})\n",
    "    content = soup.find(attrs={'id':'chr-content'})\n",
    "    \n",
    "    contents = content.find_all('p')\n",
    "    \n",
    "    content_list = list()\n",
    "    el: BS\n",
    "    for el in contents:\n",
    "        content_list.append(el.get_text())\n",
    "    text = '\\n'.join(content_list)\n",
    "    book_eng.append(text)\n",
    "len(book_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>11869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You can trace the roots of this content at n0v@lbin</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The source of this content can be linked to n0vùìÆlbùïön‚Ä¢</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This content originates from n0v3lbin‚Ä¢</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trace the roots of this material to novelb!n‚Ä¢</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The original content can be pinpointed to n0v3lbin‚Ä¢</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This material is derived from n0v¬£lbin‚Ä¢</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The source of this material is novelbin‚òÖ</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explore the genesis of this content at nùíêv@lbin‚òÖ</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You'll find the origin of this content at n0velb!n‚Ä¢</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "                                                    11869\n",
       "You can trace the roots of this content at n0v@...     64\n",
       "The source of this content can be linked to n0v...     32\n",
       "This content originates from n0v3lbin‚Ä¢                 26\n",
       "Trace the roots of this material to novelb!n‚Ä¢          22\n",
       "The original content can be pinpointed to n0v3l...     15\n",
       "This material is derived from n0v¬£lbin‚Ä¢                13\n",
       "The source of this material is novelbin‚òÖ               10\n",
       "Explore the genesis of this content at nùíêv@lbin‚òÖ        8\n",
       "You'll find the origin of this content at n0vel...      6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_eng_full = '\\n'.join(book_eng)\n",
    "a = pd.Series(book_eng_full.split('\\n')).str.strip()\n",
    "b = a.value_counts(dropna=False).to_frame().query('count > 4')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '\\n'.join(a.drop(index=a[a.isin(b.index)].index, errors='ignore').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean text:\n",
    "# test = book_eng_full.split('\\n')\n",
    "# test2 = list()\n",
    "# for row in test:\n",
    "#     if 'The source of this content is' in row:\n",
    "#         continue\n",
    "#     test2.append(row)\n",
    "# book_eng_full = '\\n'.join(test2)\n",
    "\n",
    "# book_eng_full = book_eng_full.replace('6054d257f56b520818c0fb96','')\n",
    "# book_eng_full = book_eng_full.replace('                  Ads by PubFuture','')\n",
    "# book_eng_full = book_eng_full.replace('\\n\\n','\\n').replace('\\n\\n','\\n').replace('\\n\\n','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    file=f'{name_title}.txt',\n",
    "    mode='w',\n",
    "    encoding='utf-8'\n",
    ") as file:\n",
    "    # file.write(book_eng_full)\n",
    "    file.write(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    file=f'{name_title}.txt',\n",
    "    encoding='utf-8'\n",
    ") as file:\n",
    "    book_eng_full = file.read()\n",
    "# book_eng_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bce58ce471c48bd915e6d37cbf5477b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yandexfreetranslate import YandexFreeTranslate, YandexFreeTranslateError\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from tqdm.notebook import tqdm\n",
    "from urllib.error import URLError\n",
    "\n",
    "def _worker(que: tuple) -> str:\n",
    "    for _ in range(10):\n",
    "        queue, pbar = que\n",
    "        if not queue:\n",
    "            pbar.update(1)\n",
    "            return ''\n",
    "        yt = YandexFreeTranslate(api = \"ios\")\n",
    "        try:\n",
    "            text = yt.translate(\"en\", \"ru\", queue)\n",
    "        except TimeoutError:\n",
    "            continue\n",
    "        except URLError:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "            \n",
    "        except YandexFreeTranslateError:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "            \n",
    "        # text = text.replace('/n', '')\n",
    "        pbar.update(1)\n",
    "        return text\n",
    "    raise Exception()\n",
    "\n",
    "def run_translate(lst: list[str])-> list[str]:\n",
    "    with tqdm(total=len(lst) ) as pbar:\n",
    "        l_b = list(zip(lst, ( pbar for _ in range(len(lst)))))\n",
    "        with ThreadPool(30) as pool:\n",
    "            workreturn = pool.map(_worker, l_b)\n",
    "    return workreturn\n",
    "\n",
    "lst = book_eng_full.split('\\n')\n",
    "\n",
    "text_rus = run_translate(lst)\n",
    "\n",
    "text_rus = '\\n'.join(text_rus)\n",
    "\n",
    "with open(\n",
    "    file=f'{name_title}_rus.txt',\n",
    "    mode='w',\n",
    "    encoding='utf-8'\n",
    ") as file:\n",
    "    file.write(text_rus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07fa51723cfdfdcfd96f4d831e9a58393b5ea734b6a2ccc6da0d746f7dd84b96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
