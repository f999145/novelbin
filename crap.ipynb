{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "# from selenium import webdriver\n",
    "from time import sleep as time_sleep\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import requests\n",
    "import subprocess\n",
    "from config import headers, cookies\n",
    "from pprint import pprint\n",
    "import lxml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the-mech-touch\n",
      "https://novelbin.com/ajax/chapter-option?novelId=the-mech-touch&currentChapterId\n"
     ]
    }
   ],
   "source": [
    "url_list = '''\n",
    "https://novelbin.com/b/the-mech-touch\n",
    "https://novelbin.com/b/shadow-slave\n",
    "'''.strip().split('\\n')\n",
    "\n",
    "\n",
    "url = url_list[0]\n",
    "\n",
    "host = '/'.join(url.split('/', maxsplit=3)[:3])\n",
    "name_title = url.split('/')[-1]\n",
    "print(name_title)\n",
    "\n",
    "chapters_link = f'{host}/ajax/chapter-option?novelId={name_title}&currentChapterId'\n",
    "print(chapters_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫ 5583\n",
      "–ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Å—ã–ª–∫–∞:\n",
      "https://novelbin.com/b/the-mech-touch/chapter-5583-struggles-in-cultivation\n"
     ]
    }
   ],
   "source": [
    "list_links = list()\n",
    "\n",
    "tt = requests.get(chapters_link, headers=headers, cookies=cookies)\n",
    "links_value = BS(tt.text, 'lxml')\n",
    "tb_list = links_value.find_all('option')\n",
    "elem : BS\n",
    "for elem in tb_list:\n",
    "    list_links.append(elem.get('value'))\n",
    "print('–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫',len(list_links))\n",
    "print('–ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Å—ã–ª–∫–∞:')\n",
    "print(list_links[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "driver = uc.Chrome()\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(host)\n",
    "time_sleep(1)\n",
    "driver.get(url)\n",
    "for _ in range(200):\n",
    "    page = driver.page_source\n",
    "    if not 'cloudflare.com' in page:\n",
    "        break\n",
    "    else:\n",
    "        time_sleep(1)\n",
    "else:\n",
    "    driver.quit()\n",
    "print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_eng = list()\n",
    "\n",
    "for link in list_links[400:1000]:\n",
    "    driver.get(link)\n",
    "    for _ in range(200):\n",
    "        page = driver.page_source\n",
    "        if not 'cloudflare.com' in page:\n",
    "            break\n",
    "        else:\n",
    "            time_sleep(1)\n",
    "    else:\n",
    "        driver.quit()\n",
    "    time_sleep(0.5)\n",
    "    soup = BS(page, 'html.parser')\n",
    "    novel_title = soup.find(attrs={'class':'novel-title'})\n",
    "    content = soup.find(attrs={'id':'chr-content'})\n",
    "    \n",
    "    contents = content.find_all('p')\n",
    "    \n",
    "    content_list = list()\n",
    "    el: BS\n",
    "    for el in contents:\n",
    "        content_list.append(el.get_text())\n",
    "    text = '\\n'.join(content_list)\n",
    "    book_eng.append(text)\n",
    "len(book_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>35363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This material is derived from n0vùìÆlbùïön¬∂</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The source of this material is novelbin‚òÖ</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You'll find the origin of this content at n0velb!n‚Ä¢</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trace the roots of this material to novelb!n‚Ä¢</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The original content can be pinpointed to n0v3lbin‚Ä¢</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This material is derived from n0v¬£lbin‚Ä¢</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explore the genesis of this content at nùíêv@lbin</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The source of this content can be linked to n0vùìÆlbùïön‚Ä¢</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This content originates from n0v3lbin‚Ä¢</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "                                                    35363\n",
       "This material is derived from n0vùìÆlbùïön¬∂                84\n",
       "The source of this material is novelbin‚òÖ               80\n",
       "You'll find the origin of this content at n0vel...     69\n",
       "Trace the roots of this material to novelb!n‚Ä¢          67\n",
       "The original content can be pinpointed to n0v3l...     67\n",
       "This material is derived from n0v¬£lbin‚Ä¢                66\n",
       "Explore the genesis of this content at nùíêv@lbin        65\n",
       "The source of this content can be linked to n0v...     64\n",
       "This content originates from n0v3lbin‚Ä¢                 28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_eng_full = '\\n'.join(book_eng)\n",
    "a = pd.Series(book_eng_full.split('\\n')).str.strip()\n",
    "b = a.value_counts(dropna=False).to_frame().query('count > 8')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '\\n'.join(a.drop(index=a[a.isin(b.index)].index, errors='ignore').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean text:\n",
    "# test = book_eng_full.split('\\n')\n",
    "# test2 = list()\n",
    "# for row in test:\n",
    "#     if 'The source of this content is' in row:\n",
    "#         continue\n",
    "#     test2.append(row)\n",
    "# book_eng_full = '\\n'.join(test2)\n",
    "\n",
    "# book_eng_full = book_eng_full.replace('6054d257f56b520818c0fb96','')\n",
    "# book_eng_full = book_eng_full.replace('                  Ads by PubFuture','')\n",
    "# book_eng_full = book_eng_full.replace('\\n\\n','\\n').replace('\\n\\n','\\n').replace('\\n\\n','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    file=f'{name_title}.txt',\n",
    "    mode='w',\n",
    "    encoding='utf-8'\n",
    ") as file:\n",
    "    # file.write(book_eng_full)\n",
    "    file.write(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    file=f'{name_title}.txt',\n",
    "    encoding='utf-8'\n",
    ") as file:\n",
    "    book_eng_full = file.read()\n",
    "# book_eng_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78117805fd2748bb98f0b0c603158f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36555 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yandexfreetranslate import YandexFreeTranslate, YandexFreeTranslateError\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from tqdm.notebook import tqdm\n",
    "from urllib.error import URLError\n",
    "\n",
    "def _worker(que: tuple) -> str:\n",
    "    for _ in range(10):\n",
    "        queue, pbar = que\n",
    "        if not queue:\n",
    "            pbar.update(1)\n",
    "            return ''\n",
    "        yt = YandexFreeTranslate(api = \"ios\")\n",
    "        try:\n",
    "            text = yt.translate(\"en\", \"ru\", queue)\n",
    "        except TimeoutError:\n",
    "            continue\n",
    "        except URLError:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "            \n",
    "        except YandexFreeTranslateError:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "            \n",
    "        # text = text.replace('/n', '')\n",
    "        pbar.update(1)\n",
    "        return text\n",
    "    raise Exception()\n",
    "\n",
    "def run_translate(lst: list[str])-> list[str]:\n",
    "    with tqdm(total=len(lst) ) as pbar:\n",
    "        l_b = list(zip(lst, ( pbar for _ in range(len(lst)))))\n",
    "        with ThreadPool(30) as pool:\n",
    "            workreturn = pool.map(_worker, l_b)\n",
    "    return workreturn\n",
    "\n",
    "lst = book_eng_full.split('\\n')\n",
    "\n",
    "text_rus = run_translate(lst)\n",
    "\n",
    "text_rus = '\\n'.join(text_rus)\n",
    "\n",
    "with open(\n",
    "    file=f'{name_title}_rus.txt',\n",
    "    mode='w',\n",
    "    encoding='utf-8'\n",
    ") as file:\n",
    "    file.write(text_rus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07fa51723cfdfdcfd96f4d831e9a58393b5ea734b6a2ccc6da0d746f7dd84b96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
